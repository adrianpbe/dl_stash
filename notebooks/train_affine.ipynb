{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a396833f-d375-413e-b25a-40b28523d3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dl_stash import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e9bb0-16ca-475d-b8c1-beacb5958867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bef474-5fb5-4349-bde2-2ee3c2e204da",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaling = layers.Rescaling(1/255)\n",
    "\n",
    "augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(28, 28, 1), dtype=tf.uint8),\n",
    "        scaling,\n",
    "        layers.RandomRotation (1),\n",
    "        layers.RandomPerspective(),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f3d7eb-5bc8-4345-b174-5bff23a3d0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tfds.image_classification.MNIST()\n",
    "# mnist.download_and_prepare()\n",
    "mnist_ds = mnist.as_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45001b07-b212-44c9-8c9b-f2e383e3bb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_ds.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f3583-ffa3-4ceb-97e8-db426d494080",
   "metadata": {},
   "outputs": [],
   "source": [
    "im = next(iter( mnist_ds[\"test\"].take(1) ))[\"image\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314afe3a-7177-40c5-af24-a69e5df5951c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b8d676-79eb-4572-910b-035dc1828c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "LR = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077eab9e-6aed-434b-b2be-6a718eb22d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = mnist_ds[\"train\"].map(\n",
    "        lambda x: x[\"image\"]\n",
    "    ).batch(\n",
    "        BATCH_SIZE\n",
    "    ).map(\n",
    "    lambda b: (augmentation(b), scaling(b))\n",
    ")\n",
    "val_ds = mnist_ds[\"test\"].map(\n",
    "        lambda x: x[\"image\"]\n",
    "    ).batch(\n",
    "        BATCH_SIZE\n",
    "    ).map(\n",
    "    lambda b: (augmentation(b), scaling(b))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ee2cfb-f3f9-4420-85e8-9d049161ed18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AffinedTransform(layers.Layer):\n",
    "    def __init__(self, normalize_displacement=True, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.normalize_displacement = normalize_displacement\n",
    "        # Identity transformation\n",
    "        self.default_transform = tf.constant([[1.0, 0.0, 0.0, 0.0, 1.0, 0.0]], dtype=tf.float32)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # im is (batch_size, height, width, channels)\n",
    "        # params is (batch_size, 6)\n",
    "        im, params = inputs\n",
    "        im_shape = tf.shape(im)\n",
    "        batch_size = im_shape[0]\n",
    "        height = tf.cast(im_shape[1], dtype=tf.float32)\n",
    "        width = tf.cast(im_shape[2], dtype=tf.float32)\n",
    "        if self.normalize_displacement:\n",
    "            scaling_factor = tf.convert_to_tensor([[1.0, 1.0, width, 1.0, 1.0, height]], dtype=tf.float32)\n",
    "            params = params * scaling_factor\n",
    "        params = self.default_transform + params\n",
    "        transformation_matrix = tf.reshape(params, [batch_size, 2, 3])\n",
    "        return image.affine_transform(im, transformation_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786fe0bb-2684-4583-ba6b-f6943aeac22c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# affine = AffinedTransform()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92926f44-7558-4b69-aac2-7f587f7d999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outa = affine(\n",
    "#     [\n",
    "#         tf.expand_dims(tf.cast(im, tf.float32), axis=0),\n",
    "#         tf.convert_to_tensor([[-1, 1, 0, 1, -1, 0]], dtype=tf.float32)\n",
    "#     ]\n",
    "# )[0]\n",
    "\n",
    "# plt.imshow(outa.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc50ce-1ef5-4322-ab36-292274fba0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = keras.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(28, 28, 1), dtype=tf.float32),\n",
    "        layers.Conv2D(16, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.Conv2D(32, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.Conv2D(64, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.MaxPooling2D(),\n",
    "        layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.Conv2D(256, 3, activation=\"relu\", padding=\"same\"),\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(6, activation=None),\n",
    "    ]\n",
    ")\n",
    "\n",
    "im_input = layers.Input(shape=(28, 28, 1), dtype=tf.float32)\n",
    "z_params = encoder(im_input)\n",
    "\n",
    "affine = AffinedTransform()\n",
    "im_output = affine([im_input, z_params])\n",
    "\n",
    "model = keras.Model(im_input, im_output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(LR),\n",
    "    metrics=[\"mse\"],\n",
    "    loss=\"mse\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849c84f3-42e9-4394-92a0-03f1a41c528a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_ds, epochs=50, validation_data=val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105b92f8-0026-4b90-b560-eddae8d8717b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter( val_ds.take(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bde8b-9349-4019-8f83-8ef74d092915",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a46641-65f3-4d71-bd14-469d10e6c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a92b2f0-4397-40fa-a57f-86a87a933a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predicted\n",
    "n = len(y_pred)\n",
    "offset = 16\n",
    "n = 16\n",
    "for i in range(offset, offset + n):\n",
    "    plt.figure(figsize=(12, 6 ))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(\n",
    "        x[i]\n",
    "    )\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(\n",
    "        y[i]\n",
    "    )\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.imshow(\n",
    "        y_pred[i]\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
